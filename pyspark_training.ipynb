{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "j3SN0jd2pAml",
        "outputId": "d29ab81e-7420-4580-f459-bfbc174babb0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x793d1c1d36d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://de244fc44fa2:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mydata = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"original.csv\")\n",
        "mydata.show()\n"
      ],
      "metadata": {
        "id": "KNlYZHYSqu8H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "698f4105-c479-4cb4-9620-90ecb03f8826"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+----------+------+---------------+--------------------+---------+----------+-----------+\n",
            "| id|first_name| last_name|gender|           City|            JobTitle|   Salary|  Latitude|  Longitude|\n",
            "+---+----------+----------+------+---------------+--------------------+---------+----------+-----------+\n",
            "|  1|   Melinde| Shilburne|Female|      Nowa Ruda| Assistant Professor|$57438.18|50.5774075| 16.4967184|\n",
            "|  2|  Kimberly|Von Welden|Female|         Bulgan|       Programmer II|$62846.60|48.8231572|103.5218199|\n",
            "|  3|    Alvera|  Di Boldi|Female|           null|                null|$57576.52|39.9947462|116.3397725|\n",
            "|  4|   Shannon| O'Griffin|  Male|  Divnomorskoye|Budget/Accounting...|$61489.23|44.5047212| 38.1300171|\n",
            "|  5|  Sherwood|   Macieja|  Male|      Mytishchi|            VP Sales|$63863.09|      null| 37.6489954|\n",
            "|  6|     Maris|      Folk|Female|Kinsealy-Drinan|      Civil Engineer|$30101.16|53.4266145| -6.1644997|\n",
            "|  7|     Masha|    Divers|Female|         Dachun|                null|$25090.87| 24.879416| 118.930111|\n",
            "|  8|   Goddart|     Flear|  Male|      Trélissac|Desktop Support T...|$46116.36|45.1905186|  0.7423124|\n",
            "|  9|      Roth|O'Cannavan|  Male|         Heitan|VP Product Manage...|$73697.10| 32.027934| 106.657113|\n",
            "| 10|      Bran|   Trahear|  Male|       Arbeláez|Mechanical System...|$68098.42|  4.272793| -74.416014|\n",
            "| 11|    Kylynn|   Lockart|Female|       El Cardo|Nuclear Power Eng...|$13604.63|     -5.85|-79.8833329|\n",
            "| 12|       Rey|    Meharg|Female|    Wangqingtuo|Systems Administr...|$73423.70| 39.172378| 116.931607|\n",
            "| 13|      Kerr|    Braden|  Male|      Sułkowice|Compensation Analyst|$33432.99|49.8151822| 19.3771749|\n",
            "| 14|    Mickie| Whanstall|  Male|    Springfield|Assistant Media P...|$50838.53|42.1014803|-72.5766759|\n",
            "| 15|    Kaspar|     Pally|  Male|         Chrást|  Analyst Programmer|$40163.03|49.7923299| 13.4915324|\n",
            "| 16|    Norbie|    Gwyllt|  Male|         Xijiao|              Editor|$32492.73|43.4945737|  5.8978018|\n",
            "| 17|    Claude|    Briant|Female|      Mieścisko|Research Assistan...|$51862.48|52.7441662| 17.3278637|\n",
            "| 18|     Thain|    Habbon|  Male| Foros do Trapo|     Design Engineer|$42135.67| 38.696249| -8.7098337|\n",
            "| 19|  Tiffanie|  Pattison|Female|    Jabungsisir|Senior Financial ...|$91925.08|-7.7232567|113.4686802|\n",
            "| 20|    Ettore|  Gerriets|  Male|          Pedra| Staff Accountant IV|$73921.33|40.7172049| -8.3625148|\n",
            "+---+----------+----------+------+---------------+--------------------+---------+----------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **spark.read.format(\"csv\")**\n",
        "\n",
        "Sparks read csv format file\n",
        "\n",
        "## **option(\"header\",\"true\")**\n",
        "\n",
        "Header = true allows csv file first line as header\n",
        "\n",
        "## **load(\"original.csv\")**\n",
        "\n",
        "origional.csv is the file which contains data\n",
        "\n",
        "## **mydata**\n",
        "Values or data stored in to mydata, and mydata is a dataframe\n",
        "\n",
        "## **What is a DataFrame?**\n",
        "A DataFrame is a data structure that organizes data into a 2-dimensional table of rows and columns, much like a spreadsheet.\n",
        "Every DataFrame contains a blueprint, known as a schema, that defines the name and data type of each column. Missing or incomplete values are stored as **null** values in the DataFrame.\n"
      ],
      "metadata": {
        "id": "Wwa_Sw52VH_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "mydata2 = mydata.withColumn(\"clean_city\", when(mydata.City.isNull(), 'Unknown').otherwise(mydata.City))\n",
        "mydata2.show()"
      ],
      "metadata": {
        "id": "37kan7hYsBv1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4359b3d-4e1a-43cd-968c-e8cb4f27bc6b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+----------+------+---------------+--------------------+---------+----------+-----------+---------------+\n",
            "| id|first_name| last_name|gender|           City|            JobTitle|   Salary|  Latitude|  Longitude|     clean_city|\n",
            "+---+----------+----------+------+---------------+--------------------+---------+----------+-----------+---------------+\n",
            "|  1|   Melinde| Shilburne|Female|      Nowa Ruda| Assistant Professor|$57438.18|50.5774075| 16.4967184|      Nowa Ruda|\n",
            "|  2|  Kimberly|Von Welden|Female|         Bulgan|       Programmer II|$62846.60|48.8231572|103.5218199|         Bulgan|\n",
            "|  3|    Alvera|  Di Boldi|Female|           null|                null|$57576.52|39.9947462|116.3397725|        Unknown|\n",
            "|  4|   Shannon| O'Griffin|  Male|  Divnomorskoye|Budget/Accounting...|$61489.23|44.5047212| 38.1300171|  Divnomorskoye|\n",
            "|  5|  Sherwood|   Macieja|  Male|      Mytishchi|            VP Sales|$63863.09|      null| 37.6489954|      Mytishchi|\n",
            "|  6|     Maris|      Folk|Female|Kinsealy-Drinan|      Civil Engineer|$30101.16|53.4266145| -6.1644997|Kinsealy-Drinan|\n",
            "|  7|     Masha|    Divers|Female|         Dachun|                null|$25090.87| 24.879416| 118.930111|         Dachun|\n",
            "|  8|   Goddart|     Flear|  Male|      Trélissac|Desktop Support T...|$46116.36|45.1905186|  0.7423124|      Trélissac|\n",
            "|  9|      Roth|O'Cannavan|  Male|         Heitan|VP Product Manage...|$73697.10| 32.027934| 106.657113|         Heitan|\n",
            "| 10|      Bran|   Trahear|  Male|       Arbeláez|Mechanical System...|$68098.42|  4.272793| -74.416014|       Arbeláez|\n",
            "| 11|    Kylynn|   Lockart|Female|       El Cardo|Nuclear Power Eng...|$13604.63|     -5.85|-79.8833329|       El Cardo|\n",
            "| 12|       Rey|    Meharg|Female|    Wangqingtuo|Systems Administr...|$73423.70| 39.172378| 116.931607|    Wangqingtuo|\n",
            "| 13|      Kerr|    Braden|  Male|      Sułkowice|Compensation Analyst|$33432.99|49.8151822| 19.3771749|      Sułkowice|\n",
            "| 14|    Mickie| Whanstall|  Male|    Springfield|Assistant Media P...|$50838.53|42.1014803|-72.5766759|    Springfield|\n",
            "| 15|    Kaspar|     Pally|  Male|         Chrást|  Analyst Programmer|$40163.03|49.7923299| 13.4915324|         Chrást|\n",
            "| 16|    Norbie|    Gwyllt|  Male|         Xijiao|              Editor|$32492.73|43.4945737|  5.8978018|         Xijiao|\n",
            "| 17|    Claude|    Briant|Female|      Mieścisko|Research Assistan...|$51862.48|52.7441662| 17.3278637|      Mieścisko|\n",
            "| 18|     Thain|    Habbon|  Male| Foros do Trapo|     Design Engineer|$42135.67| 38.696249| -8.7098337| Foros do Trapo|\n",
            "| 19|  Tiffanie|  Pattison|Female|    Jabungsisir|Senior Financial ...|$91925.08|-7.7232567|113.4686802|    Jabungsisir|\n",
            "| 20|    Ettore|  Gerriets|  Male|          Pedra| Staff Accountant IV|$73921.33|40.7172049| -8.3625148|          Pedra|\n",
            "+---+----------+----------+------+---------------+--------------------+---------+----------+-----------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# from pyspark.sql.functions import *\n",
        "imports pyspark.sql.functions\n",
        "\n",
        "mydata.withColumn(\"clean_city\", when(mydata.City.isNull(), 'Unknown').otherwise(mydata.City))\n",
        "\n",
        "**when(mydata.City.isNull(), 'Unknown')**\n",
        "\n",
        "When City is null, replace with Unknown\n",
        "\n",
        "**.otherwise(mydata.City))**\n",
        "\n",
        "otherwise use data from City itself\n",
        "\n",
        "**mydata.withColumn(\"clean_city\",**\n",
        "\n",
        "Add Unknown values  into clen_city a new column"
      ],
      "metadata": {
        "id": "q5EDqS_4W_69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mydata2 = mydata2.filter(mydata2.JobTitle.isNotNull())\n",
        "mydata2.show()"
      ],
      "metadata": {
        "id": "fUz9Lj9r1lcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **mydata2.filter(mydata2.JobTitle.isNotNull()**\n",
        "\n",
        "Filter if JobTitle is Not Null, show me rows with value, dont show me empty rows"
      ],
      "metadata": {
        "id": "1lbe1TxmiGDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mydata2 = mydata2.withColumn(\"clean_salary\", mydata2.Salary.substr(2,100).cast('float'))\n",
        "mydata2.show()"
      ],
      "metadata": {
        "id": "kSjUN05z2PyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **mydata2.Salary.substr(2,100).cast('float'))**\n",
        "\n",
        "Subtring removes $ sign creates new column clean_salary and typecast from string to float"
      ],
      "metadata": {
        "id": "fYEriLEzi5ZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lit\n",
        "mean = mydata2.groupBy().avg('clean_salary')\n",
        "mean.show()\n"
      ],
      "metadata": {
        "id": "iOFz12Lf3Add"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "groupBy is similar to SQL command, avg() function to get the average of clean_salary"
      ],
      "metadata": {
        "id": "6uu1n_lmkK_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = mydata2.groupby().avg('clean_salary').take(1)[0][0]\n",
        "mydata2.show()"
      ],
      "metadata": {
        "id": "6U8l3H97np7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mydata2 = mydata2.withColumn('new_salary', when(mydata2.clean_salary.isNull(), lit(mean)).otherwise(mydata2.clean_salary))\n",
        "mydata2.show()"
      ],
      "metadata": {
        "id": "mrlSNIfY4VXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "latitudes = mydata2.select('Latitude')\n",
        "latitudes.show()"
      ],
      "metadata": {
        "id": "SBvVs_E4m4ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latitudes = latitudes.filter(latitudes.Latitude.isNotNull())\n",
        "latitudes.show()"
      ],
      "metadata": {
        "id": "CE3xnD-Noe2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latitudes =latitudes.withColumn('latitude2', latitudes.Latitude.cast('float')).select('latitude2')\n",
        "latitudes.show()"
      ],
      "metadata": {
        "id": "jAiljLDpo8su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "median = np.median(latitudes.collect())\n",
        "print(median)"
      ],
      "metadata": {
        "id": "xFG9C0xrqUoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mydata2 = mydata2.withColumn('lat', when(mydata2.Latitude.isNull(), lit(median)).otherwise(mydata2.Latitude))\n",
        "mydata2.show()"
      ],
      "metadata": {
        "id": "2GY1m6aVqmKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as sqlfunc\n",
        "genders = mydata2.groupby('gender').agg(sqlfunc.avg('new_salary').alias('AvgSalary'))\n",
        "genders.show()"
      ],
      "metadata": {
        "id": "sZjNsz8OrRPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = mydata2.withColumn('female_salary', when(mydata2.gender == 'Female', mydata2.new_salary).otherwise(lit(0)))\n",
        "df = df.withColumn('male_salary', when(mydata2.gender == 'Male', mydata2.new_salary).otherwise(lit(0)))\n",
        "df.show()"
      ],
      "metadata": {
        "id": "3wS0YWQIsToX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.groupBy('JobTitle').agg(sqlfunc.avg('female_salary').alias('final_female_salary'), sqlfunc.avg('male_salary').alias('final_male_salary'))\n",
        "df.show()"
      ],
      "metadata": {
        "id": "eXriY6HkE9XM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn('delta', df.final_female_salary - df.final_male_salary)\n",
        "df.show()"
      ],
      "metadata": {
        "id": "KmbwS95GFlqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cityavg = mydata2.groupBy('City').agg(sqlfunc.avg('new_salary').alias('avg_salary'))\n",
        "\n",
        "cityavg.show()"
      ],
      "metadata": {
        "id": "N4Vh4e2pH8ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cityavg = cityavg.sort(col('avg_salary').desc())\n",
        "cityavg.show()"
      ],
      "metadata": {
        "id": "J3bHNhMMIZab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jLeHuOQ6JEWh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}